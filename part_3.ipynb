{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://c100.local:8088/proxy/application_1596895008206_26694\n",
       "SparkContext available as 'sc' (version = 2.4.0-cdh6.3.2, master = yarn, app id = application_1596895008206_26694)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{RegexTokenizer, StopWordsRemover, CountVectorizer, CountVectorizerModel, IDF, StringIndexer, ChiSqSelector, Normalizer}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit, TrainValidationSplitModel}\n",
       "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "SEED: Int = 1228952\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{RegexTokenizer, StopWordsRemover, CountVectorizer, CountVectorizerModel, IDF, StringIndexer, ChiSqSelector, Normalizer}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit, TrainValidationSplitModel}\n",
    "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "val SEED = 1228952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEVSET: String = hdfs:///user/pknees/amazon-reviews/full/reviews_devset.json\n",
       "reviewsDf: org.apache.spark.sql.DataFrame = [category: string, reviewText: string]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// load dataframe and select relevant columns\n",
    "val DEVSET = \"hdfs:///user/pknees/amazon-reviews/full/reviews_devset.json\"\n",
    "val reviewsDf = spark.read.json(DEVSET).select(\"category\", \"reviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// generate subsample of data for testing purposes\n",
    "// val subset = reviewsDf.sample(fraction=0.01, withReplacement=false, seed=SEED)\n",
    "// val reviewsDf = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            category|          reviewText|\n",
      "+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 78829\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation Steps (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_ae3cb28b63aa\n",
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_383b38ee05a1\n",
       "stopWordsRemover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_7cb044318e63\n",
       "countVectorizer: org.apache.spark.ml.feature.CountVectorizer = cntVec_c1f99181f95c\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_565e7c106b26\n",
       "selector: org.apache.spark.ml.feature.ChiSqSelector = chiSqSelector_f40b2ffd9229\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// copy of feature creation steps from part 2\n",
    "val indexer = new StringIndexer()\n",
    "    .setInputCol(\"category\")\n",
    "    .setOutputCol(\"label\")\n",
    "\n",
    "val tokenizer = new RegexTokenizer()\n",
    "    .setInputCol(\"reviewText\")\n",
    "    .setOutputCol(\"tokensRaw\")\n",
    "    .setPattern(\"[ \\t0123456789.!?,;:()\\\\[\\\\]{}\\\\-_\\\"'`~#&*%$\\\\\\\\/]+\")\n",
    "    .setToLowercase(true)\n",
    "    .setMinTokenLength(2)\n",
    "\n",
    "val stopWordsRemover = new StopWordsRemover()\n",
    "    .setInputCol(\"tokensRaw\")\n",
    "    .setOutputCol(\"tokens\")\n",
    "    .setStopWords(Array(\"a\", \"aa\", \"able\", \"about\", \"above\", \"according\", \"accordingly\", \"across\", \"actually\", \"after\", \"afterwards\", \"again\", \"against\", \"ain\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"an\", \"and\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apart\", \"appear\", \"appreciate\", \"appropriate\", \"are\", \"aren\", \"around\", \"as\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"available\", \"away\", \"awfully\", \"b\", \"bb\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bibs\", \"book\", \"both\", \"brief\", \"but\", \"by\", \"c\", \"came\", \"can\", \"cannot\", \"cant\", \"car\", \"cause\", \"causes\", \"cd\", \"certain\", \"certainly\", \"changes\", \"clearly\", \"co\", \"com\", \"come\", \"comes\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"course\", \"currently\", \"d\", \"definitely\", \"described\", \"despite\", \"did\", \"didn\", \"different\", \"do\", \"does\", \"doesn\", \"doing\", \"don\", \"done\", \"down\", \"downwards\", \"during\", \"e\", \"each\", \"edu\", \"eg\", \"eight\", \"either\", \"else\", \"elsewhere\", \"enough\", \"entirely\", \"especially\", \"et\", \"etc\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"f\", \"far\", \"few\", \"fifth\", \"first\", \"five\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"four\", \"from\", \"further\", \"furthermore\", \"g\", \"game\", \"game\", \"get\", \"gets\", \"getting\", \"given\", \"gives\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"greetings\", \"h\", \"had\", \"hadn\", \"happens\", \"hardly\", \"has\", \"hasn\", \"have\", \"haven\", \"having\", \"he\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"hi\", \"him\", \"himself\", \"his\", \"hither\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"i\", \"ie\", \"if\", \"ignored\", \"immediate\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"indicate\", \"indicated\", \"indicates\", \"inner\", \"insofar\", \"instead\", \"into\", \"inward\", \"is\", \"isn\", \"it\", \"its\", \"itself\", \"j\", \"just\", \"k\", \"keep\", \"keeps\", \"kept\", \"know\", \"known\", \"knows\", \"l\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \"let\", \"life\", \"like\", \"liked\", \"likely\", \"little\", \"ll\", \"look\", \"looking\", \"looks\", \"ltd\", \"m\", \"mainly\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"meanwhile\", \"merely\", \"might\", \"mon\", \"more\", \"moreover\", \"most\", \"mostly\", \"much\", \"must\", \"my\", \"myself\", \"n\", \"name\", \"namely\", \"nd\", \"near\", \"nearly\", \"necessary\", \"need\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"no\", \"nobody\", \"non\", \"none\", \"noone\", \"nor\", \"normally\", \"not\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"o\", \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"own\", \"p\", \"particular\", \"particularly\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"possible\", \"presumably\", \"probably\", \"provides\", \"q\", \"que\", \"quite\", \"qv\", \"r\", \"rather\", \"rd\", \"re\", \"really\", \"reasonably\", \"regarding\", \"regardless\", \"regards\", \"relatively\", \"respectively\", \"right\", \"s\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"second\", \"secondly\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"shall\", \"she\", \"should\", \"shouldn\", \"since\", \"six\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"specified\", \"specify\", \"specifying\", \"still\", \"sub\", \"such\", \"sup\", \"sure\", \"t\", \"take\", \"taken\", \"tell\", \"tends\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"theres\", \"thereupon\", \"these\", \"they\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"took\", \"toward\", \"towards\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"twice\", \"two\", \"u\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlikely\", \"until\", \"unto\", \"up\", \"upon\", \"us\", \"use\", \"used\", \"useful\", \"uses\", \"using\", \"usually\", \"v\", \"value\", \"various\", \"ve\", \"very\", \"via\", \"viz\", \"vs\", \"want\", \"wants\", \"was\", \"wasn\", \"way\", \"we\", \"welcome\", \"well\", \"went\", \"were\", \"weren\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"won\", \"wonder\", \"would\", \"wouldn\", \"x\", \"y\", \"yes\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"z\", \"zero\"))\n",
    "\n",
    "val countVectorizer = new CountVectorizer()\n",
    "    .setInputCol(\"tokens\")\n",
    "    .setOutputCol(\"featuresRaw\")\n",
    "\n",
    "val idf = new IDF()\n",
    "    .setInputCol(\"featuresRaw\")\n",
    "    .setOutputCol(\"featuresWeighted\")\n",
    "\n",
    "val selector = new ChiSqSelector()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"featuresWeighted\")\n",
    "    .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalizer: org.apache.spark.ml.feature.Normalizer = normalizer_5a634e02e072\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// apply normalizer to features using L2 norm\n",
    "val normalizer = new Normalizer()\n",
    "    .setInputCol(\"features\")\n",
    "    .setOutputCol(\"featuresNorm\")\n",
    "    .setP(2.0)  // L2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svc: org.apache.spark.ml.classification.LinearSVC = linearsvc_ee66215b518b\n",
       "ovr: org.apache.spark.ml.classification.OneVsRest = oneVsRest_5f2adc9d883c\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// setup classifier and enable use SVM in OneVsRest for multi-class problems\n",
    "val svc = new LinearSVC()\n",
    "val ovr = new OneVsRest()\n",
    "    .setClassifier(svc)\n",
    "    .setFeaturesCol(\"featuresNorm\")\n",
    "    .setLabelCol(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_762cbcb5029e\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// setup pipeline with all steps for the text classification problem\n",
    "val pipeline = new Pipeline()\n",
    "    .setStages(Array(indexer, tokenizer, stopWordsRemover, countVectorizer, idf, selector, normalizer, ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinearsvc_ee66215b518b-maxIter: 10,\n",
       "\tchiSqSelector_f40b2ffd9229-numTopFeatures: 4000,\n",
       "\tlinearsvc_ee66215b518b-regParam: 0.1,\n",
       "\tlinearsvc_ee66215b518b-standardization: true\n",
       "}, {\n",
       "\tlinearsvc_ee66215b518b-maxIter: 10,\n",
       "\tchiSqSelector_f40b2ffd9229-numTopFeatures: 400,\n",
       "\tlinearsvc_ee66215b518b-regParam: 0.1,\n",
       "\tlinearsvc_ee66215b518b-standardization: true\n",
       "}, {\n",
       "\tlinearsvc_ee66215b518b-maxIter: 1000,\n",
       "\tchiSqSelector_f40b2ffd9229-numTopFeatures: 4000,\n",
       "\tlinearsvc_ee66215b518b-regParam: 0.1,\n",
       "\tlinearsvc_ee66215b518b-standardization: true\n",
       "}, {\n",
       "\tlinearsvc_ee66215b518b-maxIter: 1000,\n",
       "\tchiSqSelector_f40b2ffd9229-numTopFeatures: 400,\n",
       "\tlinearsvc_ee66215b518b-regParam: 0.1,\n",
       "\tlinearsvc_ee66215b518b-standardization: true\n",
       "}, {\n",
       "\tlinearsvc_ee66215b518b-..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// setup parameter grid for HyperParameter optimization using feasable parameters\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "    .addGrid(selector.numTopFeatures, Array(4000, 400))\n",
    "    .addGrid(svc.regParam, Array(0.1, 1, 10)) \n",
    "    .addGrid(svc.maxIter, Array(10, 1000))\n",
    "    .addGrid(svc.standardization, Array(true, false))\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_57449ab8f980\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// evaluator for multi-class problems using f1 score\n",
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "    .setMetricName(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainValidationSplit: org.apache.spark.ml.tuning.TrainValidationSplit = tvs_9e06415eaea1\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// to save resources we use TrainValidation Split instead of Cross Validation\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "    .setEstimator(pipeline)\n",
    "    .setEvaluator(evaluator)\n",
    "    .setEstimatorParamMaps(paramGrid)\n",
    "    .setTrainRatio(0.8)\n",
    "    .setParallelism(2)\n",
    "    .setSeed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [category: string, reviewText: string]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [category: string, reviewText: string]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// split data in training and testing data (validation data is created by TrainValidationSplit for each parameter combination)\n",
    "val Array(train, test) = reviewsDf.randomSplit(Array(0.9, 0.1), seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// train model using Train Validation split and Grid Search\n",
    "val tvModel = trainValidationSplit.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// save model\n",
    "tvModel.write.overwrite().save(\"/tmp/e1228952/my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel: org.apache.spark.ml.tuning.TrainValidationSplitModel = tvs_834b603bfe97\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// load model from folder\n",
    "val myModel = TrainValidationSplitModel.load(\"/tmp/e1228952/text-processing-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [category: string, reviewText: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// predict labels\n",
    "val predictions = myModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "| 10.0|      12.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|       0.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|       2.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "| 10.0|      10.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1: Double = 0.7228184192298264\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// overall f1 score\n",
    "val f1 = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bestModel: org.apache.spark.ml.PipelineModel = pipeline_fc3776ea7eff\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bestModel = myModel.bestModel.asInstanceOf[PipelineModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res31: String = \"\"\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.explainParams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (spylon-kernel)",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
