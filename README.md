# Data Intensive Computing: Spark

Apply Spark to process large text corpora.

### Part 1 RDDs:
Calculation of chi-square values and output of the sorted top terms per category, as well as the joined dictionary, using RDDs and transformations. 


### Part 2 Datasets/DataFrames: Spark ML and Pipelines:
Convert the review texts to a classic vector space representation with TFIDF-weighted features based on the Spark DataFrame/Dataset API by building a transformation pipeline.

### Part 3 Text Classification:
Train a text Support Vector Machine classifier from the features extracted in Part 2. The goal is to learn a model that can predict the product category from a review's text.
